{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp drive/MyDrive/imgs.zip imgs.zip\n",
    "!cp drive/MyDrive/labels.zip labels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip imgs.zip\n",
    "!unzip labels.zip\n",
    "!rm -rf imgs.zip\n",
    "!rm -rf labels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "__all__ = ['UNet']\n",
    "\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class NestedUNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "__all__ = ['BCEDiceLoss']\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_ids, img_dir, mask_dir, img_ext, mask_ext, num_classes, transform=None):\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_ext = img_ext\n",
    "        self.mask_ext = mask_ext\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img = cv2.imread(os.path.join(self.img_dir, img_id + self.img_ext))\n",
    "\n",
    "        mask = []\n",
    "        for i in range(self.num_classes):\n",
    "            mask.append(cv2.imread(os.path.join(self.mask_dir,\n",
    "                        img_id + self.mask_ext), cv2.IMREAD_GRAYSCALE)[..., None])\n",
    "        mask = np.dstack(mask)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        img = img.astype('float32') / 255\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        mask = mask.astype('float32') / 255\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "        \n",
    "        return img, mask, {'img_id': img_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def dice_coef(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n",
    "    target = target.view(-1).data.cpu().numpy()\n",
    "    intersection = (output * target).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / \\\n",
    "        (output.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ['true', 1]:\n",
    "        return True\n",
    "    elif v.lower() in ['false', 0]:\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "import albumentations as albu\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--name', default=None,\n",
    "                        help='model name: (default: arch+timestamp)')\n",
    "    parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-b', '--batch_size', default=1, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 16)')\n",
    "    \n",
    "    # model\n",
    "    parser.add_argument('--arch',default='UNet')\n",
    "    parser.add_argument('--deep_supervision', default=False, type=str2bool)\n",
    "    parser.add_argument('--input_channels', default=3, type=int,\n",
    "                        help='input channels')\n",
    "    parser.add_argument('--num_classes', default=1, type=int,\n",
    "                        help='number of classes')\n",
    "    parser.add_argument('--input_w', default=96, type=int,\n",
    "                        help='image width')\n",
    "    parser.add_argument('--input_h', default=96, type=int,\n",
    "                        help='image height')\n",
    "    \n",
    "    # loss\n",
    "    parser.add_argument('--loss', default='BCEDiceLoss')\n",
    "    \n",
    "    # dataset\n",
    "    parser.add_argument('--dataset', default='dsb2018_96',\n",
    "                        help='dataset name')\n",
    "    parser.add_argument('--img_ext', default='.jpg',\n",
    "                        help='image file extension')\n",
    "    parser.add_argument('--mask_ext', default='.png',\n",
    "                        help='mask file extension')\n",
    "\n",
    "    # optimizer\n",
    "    parser.add_argument('--optimizer', default='SGD',\n",
    "                        choices=['Adam', 'SGD'],\n",
    "                        help='loss: ' +\n",
    "                        ' | '.join(['Adam', 'SGD']) +\n",
    "                        ' (default: Adam)')\n",
    "    parser.add_argument('--lr', '--learning_rate', default=1e-3, type=float,\n",
    "                        metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--nesterov', default=False, type=str2bool,\n",
    "                        help='nesterov')\n",
    "\n",
    "    # scheduler\n",
    "    parser.add_argument('--scheduler', default='CosineAnnealingLR',\n",
    "                        choices=['CosineAnnealingLR', 'ReduceLROnPlateau', 'MultiStepLR', 'ConstantLR'])\n",
    "    parser.add_argument('--min_lr', default=1e-5, type=float,\n",
    "                        help='minimum learning rate')\n",
    "    parser.add_argument('--factor', default=0.1, type=float)\n",
    "    parser.add_argument('--patience', default=2, type=int)\n",
    "    parser.add_argument('--milestones', default='1,2', type=str)\n",
    "    parser.add_argument('--gamma', default=2/3, type=float)\n",
    "    parser.add_argument('--early_stopping', default=-1, type=int,\n",
    "                        metavar='N', help='early stopping (default: -1)')\n",
    "    \n",
    "    parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "    config, unknown = parser.parse_known_args()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def train(config, train_loader, model, criterion, optimizer):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    for input, target, _ in train_loader:\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        iou = iou_score(output, target)\n",
    "\n",
    "        # compute gradient and do optimizing step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "        avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n",
    "\n",
    "\n",
    "def validate(config, val_loader, model, criterion):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input, target, _ in val_loader:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            \n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            iou = iou_score(output, target)\n",
    "\n",
    "            avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "            avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = vars(parse_args())\n",
    "    config=dict(config)\n",
    "    if config['name'] is None:\n",
    "        config['name'] = '%s_%s_woDS' % (config['dataset'], config['arch'])\n",
    "    os.makedirs('models/%s' % config['name'], exist_ok=True)\n",
    "\n",
    "    print('-' * 20)\n",
    "    for key in config:\n",
    "        print('%s: %s' % (key, config[key]))\n",
    "    print('-' * 20)\n",
    "\n",
    "    with open('models/%s/config.yml' % config['name'], 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # define loss function (criterion)\n",
    "    if config['loss'] == 'BCEWithLogitsLoss':\n",
    "        criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "    else:\n",
    "        criterion = BCEDiceLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # create model\n",
    "    print(\"=> creating model %s\" % config['arch'])\n",
    "    \n",
    "    model = NestedUNet(config['num_classes'],\n",
    "                                           config['input_channels'],\n",
    "                                           config['deep_supervision'])\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.SGD(params, lr=config['lr'], momentum=config['momentum'],\n",
    "                              nesterov=config['nesterov'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=config['epochs'], eta_min=config['min_lr'])\n",
    "\n",
    "    # Data loading code\n",
    "    img_ids = glob(os.path.join('images', '*' + config['img_ext']))\n",
    "    img_ids = [os.path.splitext(os.path.basename(p))[0] for p in img_ids]\n",
    "\n",
    "    train_img_ids, val_img_ids = train_test_split(img_ids, test_size=0.2, random_state=41)\n",
    "\n",
    "    train_transform = Compose([\n",
    "        albu.RandomRotate90(),\n",
    "        transforms.Flip(),\n",
    "        OneOf([\n",
    "            transforms.HueSaturationValue(),\n",
    "            transforms.RandomBrightness(),\n",
    "            transforms.RandomContrast(),\n",
    "        ], p=1),\n",
    "        albu.Resize(config['input_h'], config['input_w']),\n",
    "        transforms.Normalize(),\n",
    "    ])\n",
    "\n",
    "    val_transform = Compose([\n",
    "        albu.Resize(config['input_h'], config['input_w']),\n",
    "        transforms.Normalize(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = Dataset(\n",
    "        img_ids=train_img_ids,\n",
    "        img_dir='images',\n",
    "        mask_dir='masks',\n",
    "        img_ext=config['img_ext'],\n",
    "        mask_ext=config['mask_ext'],\n",
    "        num_classes=config['num_classes'],\n",
    "        transform=train_transform)\n",
    "    val_dataset = Dataset(\n",
    "        img_ids=val_img_ids,\n",
    "        img_dir='images',\n",
    "        mask_dir='masks',\n",
    "        img_ext=config['img_ext'],\n",
    "        mask_ext=config['mask_ext'],\n",
    "        num_classes=config['num_classes'],\n",
    "        transform=val_transform)\n",
    "    print(config['batch_size'])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        drop_last=False)\n",
    "\n",
    "    best_iou = 0\n",
    "    trigger = 0\n",
    "    for epoch in range(config['epochs']):\n",
    "        print('Epoch [%d/%d]' % (epoch, config['epochs']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_log = train(config, train_loader, model, criterion, optimizer)\n",
    "        # evaluate on validation set\n",
    "        val_log = validate(config, val_loader, model, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print('loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f'\n",
    "              % (train_log['loss'], train_log['iou'], val_log['loss'], val_log['iou']))\n",
    "\n",
    "        trigger += 1\n",
    "\n",
    "        if val_log['iou'] > best_iou:\n",
    "            torch.save(model.state_dict(), 'models/%s/model.pth' %\n",
    "                       config['name'])\n",
    "            best_iou = val_log['iou']\n",
    "            print(\"=> saved best model\")\n",
    "            trigger = 0\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
